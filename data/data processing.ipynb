{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2b377c",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "SPY, QQQ, AAPL, MSFT, AMZN, GOOGL, META (2010–present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0ded91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "API_KEY = 'uwQtl3txGt5BLbecq7ZbIu0ZbuitCGjc' \n",
    "TICKERS = [\"SPY\", \"QQQ\", \"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\"]\n",
    "START_DATE = \"2010-10-01\"\n",
    "END_DATE = dt.datetime.today().strftime(\"2025-10-01\") \n",
    "OUTDIR = \"./all_data\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38266112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# HELPERS\n",
    "# -----------------------------\n",
    "def _to_frame_from_polygon(items) -> pd.DataFrame:\n",
    "    \"\"\"Convert Polygon aggregate items to a DataFrame with a normalized Date index.\"\"\"\n",
    "    if not items:\n",
    "        return pd.DataFrame(columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Date\"])\n",
    "    df = pd.DataFrame([{\n",
    "        \"Date\": pd.to_datetime(it.timestamp, unit=\"ms\", utc=True).tz_convert(None).normalize(),\n",
    "        \"Open\": it.open,\n",
    "        \"High\": it.high,\n",
    "        \"Low\": it.low,\n",
    "        \"Close\": it.close,\n",
    "        \"Volume\": it.volume\n",
    "    } for it in items])\n",
    "    df = df.drop_duplicates(subset=[\"Date\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def fetch_polygon_ohlcv(ticker: str, start_date: str, end_date: str, adjusted: bool, api_key: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Fetch daily bars from Polygon. If adjusted=True, returns split/dividend-adjusted OHLC.\"\"\"\n",
    "    try:\n",
    "        from polygon import RESTClient\n",
    "    except ImportError:\n",
    "        logging.warning(\"polygon-api-client not installed; will need to fallback.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        client = RESTClient(api_key)\n",
    "        # Newer client supports list_aggs; older supports get_aggs—handle both.\n",
    "        try:\n",
    "            items = list(client.list_aggs(\n",
    "                ticker=ticker,\n",
    "                multiplier=1,\n",
    "                timespan=\"day\",\n",
    "                from_=start_date,\n",
    "                to=end_date,\n",
    "                adjusted=adjusted,\n",
    "                limit=50000\n",
    "            ))\n",
    "        except Exception:\n",
    "            # Fallback to older method signature if present in your env\n",
    "            items = client.get_aggs(ticker, 1, \"day\", start_date, end_date, limit=50000, adjusted=adjusted)\n",
    "        df = _to_frame_from_polygon(items)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Polygon fetch failed for {ticker} (adjusted={adjusted}): {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_yf_ohlcv(ticker: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Fallback using yfinance (includes Adj Close).\"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        hist = yf.Ticker(ticker).history(start=start_date, end=end_date, interval=\"1d\", auto_adjust=False)\n",
    "        if hist.empty:\n",
    "            return None\n",
    "        df = hist.reset_index().rename(columns={\n",
    "            \"Date\":\"Date\",\n",
    "            \"Open\":\"Open\",\n",
    "            \"High\":\"High\",\n",
    "            \"Low\":\"Low\",\n",
    "            \"Close\":\"Close\",\n",
    "            \"Adj Close\":\"Adj Close\",\n",
    "            \"Volume\":\"Volume\"\n",
    "        })\n",
    "        # Normalize date to midnight (no tz)\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True).dt.tz_convert(None).dt.normalize()\n",
    "        df = df[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"]]\n",
    "        df = df.drop_duplicates(subset=[\"Date\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"yfinance fetch failed for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def build_ohlcv_with_adj_close(ticker: str, start_date: str, end_date: str, api_key: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Preferred path (Polygon):\n",
    "      - Pull unadjusted bars  -> gives {Open,High,Low,Close,Volume}\n",
    "      - Pull adjusted bars    -> take adjusted Close as 'Adj Close'\n",
    "      - Join on Date\n",
    "\n",
    "    Fallback (yfinance):\n",
    "      - One call gives {Open,High,Low,Close,Adj Close,Volume}\n",
    "    \"\"\"\n",
    "    # Try Polygon first\n",
    "    unadj = fetch_polygon_ohlcv(ticker, start_date, end_date, adjusted=False, api_key=api_key)\n",
    "    adj   = fetch_polygon_ohlcv(ticker, start_date, end_date, adjusted=True,  api_key=api_key)\n",
    "\n",
    "    if unadj is not None and not unadj.empty and adj is not None and not adj.empty:\n",
    "        # Keep unadjusted OHLC + Volume, and take adjusted Close\n",
    "        left = unadj.rename(columns={\"Close\":\"Close\", \"Volume\":\"Volume\"})\n",
    "        right = adj[[\"Date\",\"Close\"]].rename(columns={\"Close\":\"Adj Close\"})\n",
    "        out = pd.merge(left, right, on=\"Date\", how=\"inner\")\n",
    "    else:\n",
    "        # Fallback to yfinance (already includes Adj Close)\n",
    "        out = fetch_yf_ohlcv(ticker, start_date, end_date)\n",
    "        if out is None or out.empty:\n",
    "            return None\n",
    "\n",
    "    # Enforce schema and dtypes\n",
    "    cols = [\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"]\n",
    "    if \"Adj Close\" not in out.columns:\n",
    "        # If adjusted not available for some reason, default Adj Close to Close\n",
    "        out[\"Adj Close\"] = out[\"Close\"]\n",
    "\n",
    "    out = out[cols].copy()\n",
    "    for c in [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\"]:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    out[\"Volume\"] = pd.to_numeric(out[\"Volume\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Clip to requested window and drop any NA rows that might linger\n",
    "    mask = (out[\"Date\"] >= pd.to_datetime(start_date)) & (out[\"Date\"] <= pd.to_datetime(end_date))\n",
    "    out = out.loc[mask].dropna(subset=[\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"]).reset_index(drop=True)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d783fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Fetching SPY (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/SPY-Daily-2010-present.csv\n",
      "INFO: Fetching QQQ (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/QQQ-Daily-2010-present.csv\n",
      "INFO: Fetching AAPL (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/AAPL-Daily-2010-present.csv\n",
      "INFO: Fetching MSFT (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/MSFT-Daily-2010-present.csv\n",
      "INFO: Fetching AMZN (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/AMZN-Daily-2010-present.csv\n",
      "INFO: Fetching GOOGL (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/GOOGL-Daily-2010-present.csv\n",
      "INFO: Fetching META (2010-10-01 → 2025-10-01) …\n",
      "INFO: Saved: ./all_data/META-Daily-2010-present.csv\n",
      "INFO: Building merged wide CSV…\n",
      "INFO: Saved merged file: ./all_data/merged_ohlcv_2010_present.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# MAIN\n",
    "# -----------------------------\n",
    "def main():\n",
    "    for t in TICKERS:\n",
    "        logging.info(f\"Fetching {t} ({START_DATE} → {END_DATE}) …\")\n",
    "        df = build_ohlcv_with_adj_close(t, START_DATE, END_DATE, API_KEY)\n",
    "        if df is None or df.empty:\n",
    "            logging.error(f\"Failed to build dataset for {t}.\")\n",
    "            continue\n",
    "        outpath = os.path.join(OUTDIR, f\"{t}-Daily-2010-present.csv\")\n",
    "        df.to_csv(outpath, index=False)\n",
    "        logging.info(f\"Saved: {outpath}\")\n",
    "\n",
    "    # Optional: create a single merged file (outer join on Date) to align calendars\n",
    "    logging.info(\"Building merged wide CSV…\")\n",
    "    frames = []\n",
    "    for t in TICKERS:\n",
    "        p = os.path.join(OUTDIR, f\"{t}-Daily-2010-present.csv\")\n",
    "        if os.path.exists(p):\n",
    "            tmp = pd.read_csv(p, parse_dates=[\"Date\"])\n",
    "            tmp = tmp.rename(columns={\n",
    "                \"Open\": f\"{t}_Open\",\n",
    "                \"High\": f\"{t}_High\",\n",
    "                \"Low\": f\"{t}_Low\",\n",
    "                \"Close\": f\"{t}_Close\",\n",
    "                \"Adj Close\": f\"{t}_AdjClose\",\n",
    "                \"Volume\": f\"{t}_Volume\",\n",
    "            })\n",
    "            frames.append(tmp)\n",
    "    if frames:\n",
    "        merged = frames[0]\n",
    "        for f in frames[1:]:\n",
    "            merged = pd.merge(merged, f, on=\"Date\", how=\"outer\")\n",
    "\n",
    "        merged = merged.sort_values(\"Date\").reset_index(drop=True)\n",
    "        merged.to_csv(os.path.join(OUTDIR, \"merged_ohlcv_2010_present.csv\"), index=False)\n",
    "        logging.info(f\"Saved merged file: {os.path.join(OUTDIR, 'merged_ohlcv_2010_present.csv')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS-3600",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
